{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f73ade52",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505bb4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install tensorflow opencv-python mediapipe numpy pandas scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc2ac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Dropout, BatchNormalization,\n",
    "    Conv1D, MaxPooling1D, GlobalAveragePooling1D,\n",
    "    LSTM, GRU, Bidirectional, Reshape, Flatten, concatenate,\n",
    "    MultiHeadAttention, LayerNormalization\n",
    ")\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# MediaPipe & OpenCV\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a303745",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d89fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ALL 111 SIGN LANGUAGE GESTURES\n",
    "# ============================================\n",
    "\n",
    "SIGNS = {\n",
    "    # Alphabet (26 signs)\n",
    "    'A': 'Letter A', 'B': 'Letter B', 'C': 'Letter C', 'D': 'Letter D',\n",
    "    'E': 'Letter E', 'F': 'Letter F', 'G': 'Letter G', 'H': 'Letter H',\n",
    "    'I': 'Letter I', 'J': 'Letter J', 'K': 'Letter K', 'L': 'Letter L',\n",
    "    'M': 'Letter M', 'N': 'Letter N', 'O': 'Letter O', 'P': 'Letter P',\n",
    "    'Q': 'Letter Q', 'R': 'Letter R', 'S': 'Letter S', 'T': 'Letter T',\n",
    "    'U': 'Letter U', 'V': 'Letter V', 'W': 'Letter W', 'X': 'Letter X',\n",
    "    'Y': 'Letter Y', 'Z': 'Letter Z',\n",
    "    \n",
    "    # Numbers (10 signs)\n",
    "    '0': 'Number 0', '1': 'Number 1', '2': 'Number 2', '3': 'Number 3',\n",
    "    '4': 'Number 4', '5': 'Number 5', '6': 'Number 6', '7': 'Number 7',\n",
    "    '8': 'Number 8', '9': 'Number 9',\n",
    "    \n",
    "    # Greetings (9 signs)\n",
    "    'HELLO': 'Hello/Hi', 'GOODBYE': 'Goodbye', 'THANK_YOU': 'Thank You',\n",
    "    'PLEASE': 'Please', 'SORRY': 'Sorry', 'WELCOME': 'Welcome',\n",
    "    'GOOD_MORNING': 'Good Morning', 'GOOD_NIGHT': 'Good Night',\n",
    "    'NICE_TO_MEET': 'Nice to Meet You',\n",
    "    \n",
    "    # Responses (9 signs)\n",
    "    'YES': 'Yes', 'NO': 'No', 'MAYBE': 'Maybe', 'OK': 'OK',\n",
    "    'DONT_KNOW': \"I Don't Know\", 'UNDERSTAND': 'I Understand',\n",
    "    'DONT_UNDERSTAND': \"I Don't Understand\", 'AGREE': 'Agree', 'DISAGREE': 'Disagree',\n",
    "    \n",
    "    # Actions (26 signs)\n",
    "    'EAT': 'Eat', 'DRINK': 'Drink', 'SLEEP': 'Sleep', 'WAKE_UP': 'Wake Up',\n",
    "    'WALK': 'Walk', 'RUN': 'Run', 'STOP': 'Stop', 'GO': 'Go', 'COME': 'Come',\n",
    "    'WAIT': 'Wait', 'SIT': 'Sit', 'STAND': 'Stand', 'HELP': 'Help',\n",
    "    'WORK': 'Work', 'PLAY': 'Play', 'LEARN': 'Learn', 'TEACH': 'Teach',\n",
    "    'READ': 'Read', 'WRITE': 'Write', 'LISTEN': 'Listen', 'SPEAK': 'Speak',\n",
    "    'WATCH': 'Watch', 'OPEN': 'Open', 'CLOSE': 'Close', 'GIVE': 'Give', 'TAKE': 'Take',\n",
    "    \n",
    "    # Emotions (10 signs)\n",
    "    'HAPPY': 'Happy', 'SAD': 'Sad', 'ANGRY': 'Angry', 'SCARED': 'Scared',\n",
    "    'SURPRISED': 'Surprised', 'TIRED': 'Tired', 'EXCITED': 'Excited',\n",
    "    'BORED': 'Bored', 'CONFUSED': 'Confused', 'PROUD': 'Proud',\n",
    "    \n",
    "    # Questions (8 signs)\n",
    "    'WHAT': 'What?', 'WHERE': 'Where?', 'WHEN': 'When?', 'WHO': 'Who?',\n",
    "    'WHY': 'Why?', 'HOW': 'How?', 'HOW_MUCH': 'How Much?', 'HOW_MANY': 'How Many?',\n",
    "    \n",
    "    # Time (7 signs)\n",
    "    'NOW': 'Now', 'LATER': 'Later', 'BEFORE': 'Before', 'AFTER': 'After',\n",
    "    'TODAY': 'Today', 'TOMORROW': 'Tomorrow', 'YESTERDAY': 'Yesterday',\n",
    "    \n",
    "    # People (10 signs)\n",
    "    'I_ME': 'I/Me', 'YOU': 'You', 'HE_SHE': 'He/She', 'WE': 'We', 'THEY': 'They',\n",
    "    'FRIEND': 'Friend', 'FAMILY': 'Family', 'MOTHER': 'Mother',\n",
    "    'FATHER': 'Father', 'CHILD': 'Child'\n",
    "}\n",
    "\n",
    "SIGN_LABELS = list(SIGNS.keys())\n",
    "NUM_SIGNS = len(SIGNS)\n",
    "\n",
    "# Sign Categories\n",
    "SIGN_CATEGORIES = {\n",
    "    'Alphabet': [chr(i) for i in range(65, 91)],\n",
    "    'Numbers': [str(i) for i in range(10)],\n",
    "    'Greetings': ['HELLO', 'GOODBYE', 'THANK_YOU', 'PLEASE', 'SORRY', 'WELCOME', \n",
    "                  'GOOD_MORNING', 'GOOD_NIGHT', 'NICE_TO_MEET'],\n",
    "    'Responses': ['YES', 'NO', 'MAYBE', 'OK', 'DONT_KNOW', 'UNDERSTAND', \n",
    "                  'DONT_UNDERSTAND', 'AGREE', 'DISAGREE'],\n",
    "    'Actions': ['EAT', 'DRINK', 'SLEEP', 'WAKE_UP', 'WALK', 'RUN', 'STOP', 'GO', 'COME',\n",
    "                'WAIT', 'SIT', 'STAND', 'HELP', 'WORK', 'PLAY', 'LEARN', 'TEACH',\n",
    "                'READ', 'WRITE', 'LISTEN', 'SPEAK', 'WATCH', 'OPEN', 'CLOSE', 'GIVE', 'TAKE'],\n",
    "    'Emotions': ['HAPPY', 'SAD', 'ANGRY', 'SCARED', 'SURPRISED', 'TIRED', \n",
    "                 'EXCITED', 'BORED', 'CONFUSED', 'PROUD'],\n",
    "    'Questions': ['WHAT', 'WHERE', 'WHEN', 'WHO', 'WHY', 'HOW', 'HOW_MUCH', 'HOW_MANY'],\n",
    "    'Time': ['NOW', 'LATER', 'BEFORE', 'AFTER', 'TODAY', 'TOMORROW', 'YESTERDAY'],\n",
    "    'People': ['I_ME', 'YOU', 'HE_SHE', 'WE', 'THEY', 'FRIEND', 'FAMILY', \n",
    "               'MOTHER', 'FATHER', 'CHILD']\n",
    "}\n",
    "\n",
    "print(f\"âœ… Total Signs: {NUM_SIGNS}\")\n",
    "print(f\"ðŸ“ Categories: {len(SIGN_CATEGORIES)}\")\n",
    "for cat, signs in SIGN_CATEGORIES.items():\n",
    "    print(f\"   â€¢ {cat}: {len(signs)} signs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e22671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# PROJECT CONFIGURATION\n",
    "# ============================================\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = 'data'\n",
    "RAW_DATA_DIR = os.path.join(DATA_DIR, 'raw')\n",
    "PROCESSED_DATA_DIR = os.path.join(DATA_DIR, 'processed')\n",
    "MODELS_DIR = 'models'\n",
    "OUTPUTS_DIR = 'outputs'\n",
    "DATASET_CSV = os.path.join(RAW_DATA_DIR, 'sign_dataset.csv')\n",
    "\n",
    "# Create directories\n",
    "for d in [RAW_DATA_DIR, PROCESSED_DATA_DIR, MODELS_DIR, OUTPUTS_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# MediaPipe Settings\n",
    "MP_MAX_HANDS = 2\n",
    "MP_MIN_DETECTION_CONF = 0.7\n",
    "MP_MIN_TRACKING_CONF = 0.5\n",
    "\n",
    "# Features\n",
    "NUM_LANDMARKS = 21\n",
    "COORDS_PER_LANDMARK = 3\n",
    "FEATURES_PER_HAND = NUM_LANDMARKS * COORDS_PER_LANDMARK  # 63\n",
    "TOTAL_FEATURES = FEATURES_PER_HAND * MP_MAX_HANDS  # 126\n",
    "\n",
    "# Training Settings\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "TEST_SPLIT = 0.15\n",
    "VALIDATION_SPLIT = 0.15\n",
    "\n",
    "# Detection Settings\n",
    "CONFIDENCE_THRESHOLD = 0.6\n",
    "PREDICTION_BUFFER_SIZE = 5\n",
    "\n",
    "print(\"âœ… Configuration loaded\")\n",
    "print(f\"ðŸ“Š Features per sample: {TOTAL_FEATURES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908542a8",
   "metadata": {},
   "source": [
    "## 3. Data Collection (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68a714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandDetector:\n",
    "    \"\"\"MediaPipe hand detection wrapper\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.mp_hands = mp.solutions.hands\n",
    "        self.mp_draw = mp.solutions.drawing_utils\n",
    "        \n",
    "        self.hands = self.mp_hands.Hands(\n",
    "            static_image_mode=False,\n",
    "            max_num_hands=MP_MAX_HANDS,\n",
    "            min_detection_confidence=MP_MIN_DETECTION_CONF,\n",
    "            min_tracking_confidence=MP_MIN_TRACKING_CONF\n",
    "        )\n",
    "    \n",
    "    def detect(self, frame):\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        return self.hands.process(rgb)\n",
    "    \n",
    "    def extract_landmarks(self, frame):\n",
    "        results = self.detect(frame)\n",
    "        \n",
    "        left_hand = np.zeros(FEATURES_PER_HAND)\n",
    "        right_hand = np.zeros(FEATURES_PER_HAND)\n",
    "        hand_detected = False\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            hand_detected = True\n",
    "            \n",
    "            for idx, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
    "                if idx >= len(results.multi_handedness):\n",
    "                    continue\n",
    "                \n",
    "                hand_label = results.multi_handedness[idx].classification[0].label\n",
    "                \n",
    "                landmarks = []\n",
    "                for lm in hand_landmarks.landmark:\n",
    "                    landmarks.extend([lm.x, lm.y, lm.z])\n",
    "                \n",
    "                landmarks = np.array(landmarks)\n",
    "                \n",
    "                if hand_label == 'Left':\n",
    "                    left_hand = landmarks\n",
    "                else:\n",
    "                    right_hand = landmarks\n",
    "        \n",
    "        features = np.concatenate([left_hand, right_hand])\n",
    "        return features, results, hand_detected\n",
    "    \n",
    "    def draw_landmarks(self, frame, results):\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                self.mp_draw.draw_landmarks(\n",
    "                    frame, hand_landmarks,\n",
    "                    self.mp_hands.HAND_CONNECTIONS\n",
    "                )\n",
    "        return frame\n",
    "    \n",
    "    def release(self):\n",
    "        self.hands.close()\n",
    "\n",
    "print(\"âœ… HandDetector class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdef600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synthetic_dataset(num_samples=1000, signs_to_use=None):\n",
    "    \"\"\"\n",
    "    Create synthetic dataset for testing/demonstration\n",
    "    In real usage, collect actual hand landmark data\n",
    "    \"\"\"\n",
    "    if signs_to_use is None:\n",
    "        signs_to_use = SIGN_LABELS[:20]  # Use first 20 signs\n",
    "    \n",
    "    print(f\"Creating synthetic dataset with {len(signs_to_use)} signs...\")\n",
    "    \n",
    "    data = []\n",
    "    samples_per_sign = num_samples // len(signs_to_use)\n",
    "    \n",
    "    for sign in signs_to_use:\n",
    "        # Generate base pattern for this sign\n",
    "        base_pattern = np.random.randn(TOTAL_FEATURES) * 0.5\n",
    "        \n",
    "        for _ in range(samples_per_sign):\n",
    "            # Add variation to base pattern\n",
    "            noise = np.random.randn(TOTAL_FEATURES) * 0.1\n",
    "            features = base_pattern + noise\n",
    "            \n",
    "            row = {\n",
    "                'sign': sign,\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "            for i, f in enumerate(features):\n",
    "                row[f'feature_{i}'] = f\n",
    "            \n",
    "            data.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(DATASET_CSV, index=False)\n",
    "    \n",
    "    print(f\"âœ… Created {len(df)} samples for {df['sign'].nunique()} signs\")\n",
    "    print(f\"ðŸ’¾ Saved to: {DATASET_CSV}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create sample dataset\n",
    "# Uncomment to create synthetic data for testing\n",
    "# df = create_synthetic_dataset(num_samples=2000, signs_to_use=SIGN_LABELS[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85950237",
   "metadata": {},
   "source": [
    "## 4. Data Loading & Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb509360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or create dataset\n",
    "if os.path.exists(DATASET_CSV):\n",
    "    df = pd.read_csv(DATASET_CSV)\n",
    "    print(f\"âœ… Loaded existing dataset: {len(df)} samples\")\n",
    "else:\n",
    "    print(\"âš ï¸ No dataset found. Creating synthetic data for demonstration...\")\n",
    "    df = create_synthetic_dataset(num_samples=3000, signs_to_use=SIGN_LABELS[:30])\n",
    "\n",
    "print(f\"\\nðŸ“Š Dataset Summary:\")\n",
    "print(f\"   Total samples: {len(df)}\")\n",
    "print(f\"   Total signs: {df['sign'].nunique()}\")\n",
    "print(f\"   Features: {len([c for c in df.columns if c.startswith('feature_')])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f652aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "sign_counts = df['sign'].value_counts()\n",
    "\n",
    "if len(sign_counts) > 30:\n",
    "    sign_counts[:30].plot(kind='bar', color='steelblue')\n",
    "    plt.title('Dataset Distribution (Top 30 Signs)', fontsize=14, fontweight='bold')\n",
    "else:\n",
    "    sign_counts.plot(kind='bar', color='steelblue')\n",
    "    plt.title('Dataset Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.xlabel('Sign')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSamples per sign:\")\n",
    "print(sign_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c62e564",
   "metadata": {},
   "source": [
    "## 5. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcade631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and labels\n",
    "feature_cols = [col for col in df.columns if col.startswith('feature_')]\n",
    "\n",
    "X = df[feature_cols].values\n",
    "y = df['sign'].values\n",
    "\n",
    "# Handle missing values\n",
    "X = np.nan_to_num(X, nan=0.0)\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9ac3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Classes: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6120fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "def augment_data(X, y, augmentation_factor=2):\n",
    "    \"\"\"Augment data with noise and scaling\"\"\"\n",
    "    print(f\"Augmenting data (factor: {augmentation_factor})...\")\n",
    "    \n",
    "    augmented_X = [X]\n",
    "    augmented_y = [y]\n",
    "    \n",
    "    for i in range(augmentation_factor - 1):\n",
    "        # Add Gaussian noise\n",
    "        noise = np.random.normal(0, 0.02, X.shape)\n",
    "        X_noisy = X + noise\n",
    "        \n",
    "        # Add scaling variation\n",
    "        scale = np.random.uniform(0.95, 1.05, X.shape)\n",
    "        X_scaled = X * scale\n",
    "        \n",
    "        augmented_X.extend([X_noisy, X_scaled])\n",
    "        augmented_y.extend([y, y])\n",
    "    \n",
    "    X_aug = np.vstack(augmented_X)\n",
    "    y_aug = np.hstack(augmented_y)\n",
    "    \n",
    "    print(f\"Augmented: {len(X)} â†’ {len(X_aug)} samples\")\n",
    "    return X_aug, y_aug\n",
    "\n",
    "X_aug, y_aug = augment_data(X, y_encoded, augmentation_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321f128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_aug)\n",
    "\n",
    "print(f\"Feature range: [{X_scaled.min():.2f}, {X_scaled.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94a9b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X_scaled, y_aug, test_size=TEST_SPLIT, random_state=42, stratify=y_aug\n",
    ")\n",
    "\n",
    "val_ratio = VALIDATION_SPLIT / (1 - TEST_SPLIT)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=val_ratio, random_state=42, stratify=y_trainval\n",
    ")\n",
    "\n",
    "print(f\"\\nData Split:\")\n",
    "print(f\"  Train: {X_train.shape[0]} samples\")\n",
    "print(f\"  Val:   {X_val.shape[0]} samples\")\n",
    "print(f\"  Test:  {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0765bb",
   "metadata": {},
   "source": [
    "## 6. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b769d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(num_features, num_classes):\n",
    "    \"\"\"1D CNN Model\"\"\"\n",
    "    inputs = Input(shape=(num_features,))\n",
    "    \n",
    "    x = Reshape((num_features, 1))(inputs)\n",
    "    \n",
    "    x = Conv1D(256, 3, activation='relu', padding='same', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv1D(128, 3, activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv1D(64, 3, activation='relu', padding='same')(x)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    \n",
    "    x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs, name='CNN_Model')\n",
    "    model.compile(optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_lstm_model(num_features, num_classes):\n",
    "    \"\"\"Bidirectional LSTM Model\"\"\"\n",
    "    inputs = Input(shape=(num_features,))\n",
    "    \n",
    "    x = Reshape((42, 3))(inputs)  # 42 landmarks * 3 coords\n",
    "    \n",
    "    x = Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=l2(0.001)))(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    \n",
    "    x = Bidirectional(LSTM(64, return_sequences=False))(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    \n",
    "    x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    \n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    \n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs, name='LSTM_Model')\n",
    "    model.compile(optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_hybrid_model(num_features, num_classes):\n",
    "    \"\"\"Hybrid CNN + LSTM + GRU Model\"\"\"\n",
    "    inputs = Input(shape=(num_features,))\n",
    "    \n",
    "    # CNN Branch\n",
    "    x_cnn = Reshape((num_features, 1))(inputs)\n",
    "    x_cnn = Conv1D(64, 3, activation='relu', padding='same')(x_cnn)\n",
    "    x_cnn = BatchNormalization()(x_cnn)\n",
    "    x_cnn = MaxPooling1D(2)(x_cnn)\n",
    "    x_cnn = Conv1D(128, 3, activation='relu', padding='same')(x_cnn)\n",
    "    x_cnn = GlobalAveragePooling1D()(x_cnn)\n",
    "    \n",
    "    # LSTM Branch\n",
    "    x_lstm = Reshape((42, 3))(inputs)\n",
    "    x_lstm = LSTM(64, return_sequences=True)(x_lstm)\n",
    "    x_lstm = LSTM(64, return_sequences=False)(x_lstm)\n",
    "    \n",
    "    # GRU Branch\n",
    "    x_gru = Reshape((42, 3))(inputs)\n",
    "    x_gru = GRU(64, return_sequences=False)(x_gru)\n",
    "    \n",
    "    # Concatenate\n",
    "    x = concatenate([x_cnn, x_lstm, x_gru])\n",
    "    \n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs, name='Hybrid_Model')\n",
    "    model.compile(optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "print(\"âœ… Model builders defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060993ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select and create model\n",
    "MODEL_TYPE = 'hybrid'  # Options: 'cnn', 'lstm', 'hybrid'\n",
    "\n",
    "model_builders = {\n",
    "    'cnn': create_cnn_model,\n",
    "    'lstm': create_lstm_model,\n",
    "    'hybrid': create_hybrid_model\n",
    "}\n",
    "\n",
    "model = model_builders[MODEL_TYPE](X_train.shape[1], num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a17fb3",
   "metadata": {},
   "source": [
    "## 7. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897bdfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n",
    "]\n",
    "\n",
    "print(\"Starting training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e9dbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1a218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].plot(history.history['accuracy'], label='Train', linewidth=2)\n",
    "axes[0].plot(history.history['val_accuracy'], label='Validation', linewidth=2)\n",
    "axes[0].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss\n",
    "axes[1].plot(history.history['loss'], label='Train', linewidth=2)\n",
    "axes[1].plot(history.history['val_loss'], label='Validation', linewidth=2)\n",
    "axes[1].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUTS_DIR, 'training_history.png'), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5585fe2f",
   "metadata": {},
   "source": [
    "## 8. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e7a2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f\"\\nðŸ“Š Test Results:\")\n",
    "print(f\"   Loss: {test_loss:.4f}\")\n",
    "print(f\"   Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59700935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "y_pred = np.argmax(model.predict(X_test, verbose=0), axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nðŸ“‹ Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_names[:len(np.unique(y_test))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ad2ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "if num_classes > 20:\n",
    "    sns.heatmap(cm, cmap='Blues', cbar=True)\n",
    "    plt.title(f'Confusion Matrix ({num_classes} classes)', fontsize=14, fontweight='bold')\n",
    "else:\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "               xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUTS_DIR, 'confusion_matrix.png'), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee02370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_path = os.path.join(MODELS_DIR, f'{MODEL_TYPE}_sign_model.h5')\n",
    "model.save(model_path)\n",
    "print(f\"âœ… Model saved: {model_path}\")\n",
    "\n",
    "# Save preprocessors\n",
    "import pickle\n",
    "\n",
    "with open(os.path.join(MODELS_DIR, 'label_encoder.pkl'), 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "with open(os.path.join(MODELS_DIR, 'scaler.pkl'), 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"âœ… Preprocessors saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de095612",
   "metadata": {},
   "source": [
    "## 9. Real-time Detection (Run in separate Python script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d358941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-time detection code\n",
    "# Note: Run this in a separate Python script for best results\n",
    "\n",
    "def run_detection():\n",
    "    \"\"\"Run real-time sign language detection\"\"\"\n",
    "    \n",
    "    # Load model and preprocessors\n",
    "    loaded_model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    with open(os.path.join(MODELS_DIR, 'label_encoder.pkl'), 'rb') as f:\n",
    "        loaded_encoder = pickle.load(f)\n",
    "    \n",
    "    with open(os.path.join(MODELS_DIR, 'scaler.pkl'), 'rb') as f:\n",
    "        loaded_scaler = pickle.load(f)\n",
    "    \n",
    "    detector = HandDetector()\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "    \n",
    "    print(\"\\nðŸŽ¥ Starting detection. Press 'q' to quit.\")\n",
    "    \n",
    "    from collections import deque\n",
    "    prediction_buffer = deque(maxlen=5)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame = cv2.flip(frame, 1)\n",
    "        features, results, hand_detected = detector.extract_landmarks(frame)\n",
    "        frame = detector.draw_landmarks(frame, results)\n",
    "        \n",
    "        sign_name = \"No hand detected\"\n",
    "        confidence = 0.0\n",
    "        \n",
    "        if hand_detected:\n",
    "            # Preprocess\n",
    "            features_scaled = loaded_scaler.transform(features.reshape(1, -1))\n",
    "            \n",
    "            # Predict\n",
    "            predictions = loaded_model.predict(features_scaled, verbose=0)\n",
    "            class_idx = np.argmax(predictions[0])\n",
    "            confidence = predictions[0][class_idx]\n",
    "            \n",
    "            prediction_buffer.append((class_idx, confidence))\n",
    "            \n",
    "            # Get smoothed prediction\n",
    "            from collections import Counter\n",
    "            preds = [p[0] for p in prediction_buffer]\n",
    "            most_common = Counter(preds).most_common(1)[0][0]\n",
    "            avg_conf = np.mean([c for p, c in prediction_buffer if p == most_common])\n",
    "            \n",
    "            if avg_conf >= CONFIDENCE_THRESHOLD:\n",
    "                sign_name = loaded_encoder.inverse_transform([most_common])[0]\n",
    "                confidence = avg_conf\n",
    "        \n",
    "        # Draw UI\n",
    "        cv2.rectangle(frame, (0, 0), (640, 100), (50, 50, 50), -1)\n",
    "        cv2.putText(frame, f\"Sign: {sign_name}\", (20, 50),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f\"Confidence: {confidence*100:.1f}%\", (20, 85),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 1)\n",
    "        \n",
    "        cv2.imshow('Sign Language Detection', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    detector.release()\n",
    "\n",
    "# Uncomment to run detection\n",
    "# run_detection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f35fb5",
   "metadata": {},
   "source": [
    "## ðŸ“Š Summary\n",
    "\n",
    "This notebook provides a complete pipeline for:\n",
    "\n",
    "1. **111 Sign Language Gestures** - A-Z, 0-9, and 75 custom signs\n",
    "2. **Data Collection** - Using MediaPipe hand landmarks (126 features)\n",
    "3. **Preprocessing** - Augmentation, normalization, train-test split\n",
    "4. **Multiple Models** - CNN, LSTM, Hybrid architectures\n",
    "5. **Training** - With callbacks for early stopping and learning rate reduction\n",
    "6. **Evaluation** - Accuracy, classification report, confusion matrix\n",
    "7. **Real-time Detection** - Live webcam inference\n",
    "\n",
    "For production use:\n",
    "- Collect real hand landmark data using the `src/data_collection.py` module\n",
    "- Train with more epochs and larger dataset\n",
    "- Use the `main.py` script for interactive menu-driven access"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
